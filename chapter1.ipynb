{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "00：文字列”stressed”の文字を逆に（末尾から先頭に向かって）並べた文字列を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings00 = \"stressed\"\n",
    "\n",
    "reversed_strings = strings00[::-1]\n",
    "reversed_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01：「パタトクカシーー」という文字列の1,3,5,7文字目を取り出して連結した文字列を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings01 = \"パタトクカシーー\"\n",
    "\n",
    "odd_strings = strings01[0::2]\n",
    "odd_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "02：「パトカー」＋「タクシー」の文字を先頭から交互に連結して文字列「パタトクカシーー」を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings02_1 = \"パトカー\"\n",
    "strings02_2 = \"タクシー\"\n",
    "\n",
    "sum_strings = \"\"\n",
    "\n",
    "for i in range(len(strings02_1)):\n",
    "    sum_strings += strings02_1[i] \n",
    "    sum_strings += strings02_2[i]\n",
    "\n",
    "sum_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "03：“Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.”という文を単語に分解し，各単語の（アルファベットの）文字数を先頭から出現順に並べたリストを作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8, 9, 7, 9]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence03 = \"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"\n",
    "sentence03 = sentence03.replace(\",\",\"\")\n",
    "sentence03 = sentence03.replace(\".\",\"\")\n",
    "word_list = sentence03.split(\" \")\n",
    "\n",
    "length_list = [0] * len(word_list)\n",
    "for i in range(len(word_list)):\n",
    "    length_list[i] = len(word_list[i])\n",
    "length_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "04：“Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.”という文を単語に分解し，1, 5, 6, 7, 8, 9, 15, 16, 19番目の単語は先頭の1文字，それ以外の単語は先頭の2文字を取り出し，取り出した文字列から単語の位置（先頭から何番目の単語か）への連想配列（辞書型もしくはマップ型）を作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'H': 1, 'He': 2, 'Li': 3, 'Be': 4, 'B': 5, 'C': 6, 'N': 7, 'O': 8, 'F': 9, 'Ne': 10, 'Na': 11, 'Mi': 12, 'Al': 13, 'Si': 14, 'P': 15, 'S': 16, 'Cl': 17, 'Ar': 18, 'K': 19, 'Ca': 20}\n"
     ]
    }
   ],
   "source": [
    "sentence04 = \"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"\n",
    "sentence04 = sentence04.replace(\",\",\"\")\n",
    "sentence04 = sentence04.replace(\".\",\"\")\n",
    "\n",
    "pre_atom = sentence04.split(\" \")\n",
    "num_list = [1,5,6,7,8,9,15,16,19]\n",
    "\n",
    "ans_dict = {}\n",
    "\n",
    "for i in range(len(pre_atom)):\n",
    "    if i+1 in(num_list):\n",
    "        at = pre_atom[i][0]\n",
    "        n = i+1\n",
    "        ans_dict[at] = n\n",
    "    else:\n",
    "        at = pre_atom[i][0:2]\n",
    "        n = i+1\n",
    "        ans_dict[at] = n\n",
    "print(ans_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "05:与えられたシーケンス（文字列やリストなど）からn-gramを作る関数を作成せよ．この関数を用い，”I am an NLPer”という文から単語bi-gram，文字bi-gramを得よ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence05 = \"I am an NLPer\"\n",
    "\n",
    "def ngram (n, type, sentence):\n",
    "    if type == 0: # 文字ngram\n",
    "        character = sentence.replace(\" \", \"\")\n",
    "        result_list = [\"\"] * (len(character) - n + 1)\n",
    "        for i in range((len(character) - n + 1)):\n",
    "            result_list[i] = character[i:i+2]\n",
    "    elif type == 1: # 単語ngram\n",
    "        words = sentence.split(\" \")\n",
    "        result_list = [\"\"] * (len(words) - n + 1)\n",
    "        for i in range((len(words) - n + 1)):\n",
    "            result_list[i] = words[i:i+2]\n",
    "        \n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ia', 'am', 'ma', 'an', 'nN', 'NL', 'LP', 'Pe', 'er']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram(2, 0, sentence05) #文字bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I', 'am'], ['am', 'an'], ['an', 'NLPer']]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram(2, 1, sentence05) #単語bigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "06:“paraparaparadise”と”paragraph”に含まれる文字bi-gramの集合を，それぞれ, XとYとして求め，XとYの和集合，積集合，差集合を求めよ．さらに，’se’というbi-gramがXおよびYに含まれるかどうかを調べよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ph', 'ar', 'ra', 'ag', 'ap', 'se', 'is', 'di', 'pa', 'ad', 'gr'} {'ap', 'pa', 'ar', 'ra'} {'is', 'se', 'di', 'ad'} True False\n"
     ]
    }
   ],
   "source": [
    "sentence06_1 = \"paraparaparadise\"\n",
    "sentence06_2 = \"paragraph\"\n",
    "\n",
    "X = set(ngram(2, 0, sentence06_1))\n",
    "Y = set(ngram(2, 0, sentence06_2))\n",
    "\n",
    "sumSet = X | Y\n",
    "mulSet = X & Y\n",
    "difSet = X - Y\n",
    "se_inX = \"se\" in X\n",
    "se_inY = \"se\" in Y\n",
    "print(sumSet, mulSet, difSet, se_inX, se_inY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "07:引数x, y, zを受け取り「x時のyはz」という文字列を返す関数を実装せよ．さらに，x=12, y=”気温”, z=22.4として，実行結果を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12時の気温は22.4'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fn(x, y, z):\n",
    "    return f\"{x}時の{y}は{z}\"\n",
    "\n",
    "fn(12, \"気温\", 22.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "08:与えられた文字列の各文字を，以下の仕様で変換する関数cipherを実装せよ．\n",
    "\n",
    "・英小文字ならば(219 - 文字コード)の文字に置換\n",
    "\n",
    "・その他の文字はそのまま出力\n",
    "\n",
    "この関数を用い，英語のメッセージを暗号化・復号化せよ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cipher(strings):\n",
    "    char_list = list(strings)\n",
    "    for i in range(len(char_list)):\n",
    "        if char_list[i].islower():\n",
    "            char_list[i] = chr(219 - ord(char_list[i]))\n",
    "    result = \"\".join(char_list)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The high and low'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode = cipher(\"The high and low\")\n",
    "decode = cipher(encode)\n",
    "decode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "09:スペースで区切られた単語列に対して，各単語の先頭と末尾の文字は残し，それ以外の文字の順序をランダムに並び替えるプログラムを作成せよ．ただし，長さが４以下の単語は並び替えないこととする．適当な英語の文（例えば”I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind .”）を与え，その実行結果を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I c'nuoldt blieeve that I culod alclauty uasrentdnd what I was rdaeing : the pnneeoahml pweor of the hamun mind .\""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "sentence09 = \"I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"\n",
    "\n",
    "def typoglycemia(sentence):\n",
    "    word_list = sentence.split(\" \")\n",
    "    for i in range(len(word_list)):\n",
    "        if len(word_list[i]) > 4:\n",
    "            word = word_list[i] \n",
    "            mid_char = list(word[1:-1])\n",
    "            random.shuffle(mid_char)\n",
    "            mid_char_rd = \"\".join(mid_char)\n",
    "            return_word_list = [word[0], mid_char_rd, word[-1]]\n",
    "            return_word = \"\".join(return_word_list)\n",
    "            word_list[i] = return_word\n",
    "    return_sentence = \" \".join(word_list)\n",
    "    return return_sentence\n",
    "\n",
    "typoglycemia(sentence09)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
